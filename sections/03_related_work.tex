\section{Trabalhos Relacionados}

\todoin[size=\scriptsize,linecolor=gray,backgroundcolor=gray!25,bordercolor=gray]{
\begin{center}
\begin{tabular}{lcp{7cm}}
\multicolumn{1}{c}{\textbf{Artigo}} & \multicolumn{1}{c}{\textbf{Níveis de Cache}} & \multicolumn{1}{c}{\textbf{Descrição}} \\
\cite{Smullen2011} & L1,L2,L3 & Primeiro artigo a abordar STT-RAM volátil \\
\cite{li2011} & L1 e L2 & \\
\cite{Sun2011} & L1, L2 e L3 & \\
\cite{Jog2012} & L2 & \\
\cite{Li2013} & L2 & \\
\cite{Chang2013} & L3 & \\
\cite{Li2015} & L1 & \\
\cite{Kim2015} & & \\
\cite{qiu2016} & & \\
\cite{kim2016} & & \\
\end{tabular}
\end{center}
}

% Smullen2011 %

O primeiro trabalho que faz um estudo e apresenta o conceito de STT-RAM volátil é visto em~\cite{Smullen2011}. Este trabalho primeiramente explica como a STT-RAM pode ser volátil -- efeito atingido através da redução da área planar da camada livre da MTJ da célula de memória. O artigo apresenta um modelo de STT-RAM volátil, exibe técnicas para otimização desta memória para prover melhorias no desempenho da escrita. Este modelo é testado em todos os níveis de \textit{cache} nas questões de desempenho, energia e \textit{energy-delay}. Por fim, com a perda de retenção da STT-RAM, os dados em memória não podem ser perdidos. Com isto, o trabalho estuda um esquema simples de \textit{refresh} que adiciona pouco \textit{overhead} sobre o sistema de memória.

A primeira avaliação é efetuada sobre a relação entre as velocidades de leitura e escrita de uma célula STT-RAM. Chega-se à conclusão de que a fim de reduzir a latência das escritas, deve-se aumentar o tempo das leituras sem que isto deteriore o desempenho geral das leituras. Fazendo-se o processo reverso, i.e., aumentando o tempo de escrita numa célula da STT-RAM, a latência de leitura tende a diminuir. Outra análise é feita diminuindo a área planar da célula STT-RAM, sendo esta diretamente proporcional ao tempo de retenção do dado (Uma célula de $10F^2$ tem tempo de retenção de somente $56\mu s$). Ao reduzir o tempo de retenção, melhorias são percebidas na latência de escritas, bem como na energia em operações de leitura e escrita.

O trabalho faz então avaliações do impacto do uso da STT-RAM volátil através de simulações com \textit{benchmarks}. Primeiramente, efetua-se a troca de todas as \textit{caches} SRAM por STT-RAM voláteis, verificando que em questões de desempenho a maioria dos casos estudados existem perdas devido ao acréscimo nos tempos de escrita em memória. Em contrapartida, há uma redução de mais de 3x na fuga de energia ao usar STT-RAM. Outras avaliações que geraram resultados também foram realizadas, porém considerando hierarquias de memórias híbridas, podendo incluir tanto SRAM como os diferentes modelos de STT-RAM mostrados anteriormente. Os modelos de \textit{cache} híbridos com STT-RAM de área $19F^2$ e $10F^2$ conseguem ter desempenho igual ou melhor comparado com \textit{caches} SRAM. Nestes modelos híbridos, a redução do consumo energético é menor se comparada com \textit{caches} puramente de tecnologia STT-RAM, porém ainda assim há ganhos consideráveis comparando com as SRAM.

Por fim, considerando que a memória estudada passa a ser volátil, o artigo propõe e utiliza-se de uma política de \textit{refresh} simples, tal qual a DRAM, iterando por cada linha para aplicar um \textit{refresh}. A última análise do trabalho envolve algumas configurações de hierarquias de \textit{caches} as quais são testadas com este esquema de \textit{refresh}, sendo comparadas com as hierarquias já visas anteriormente, bem como o \textit{baseline} (\textit {caches} SRAM). Conclui-se que ao utilizar \textit{designs} de \textit{caches} STT-RAM de $19F^2$ com \textit{refresh} conseguem superar tanto no consumo quanto no desempenho os projetos de $32F^2$, além de prover melhor desempenho. 

% Li2011 %

No trabalho apresentado em \cite{li2011}, é realizado um \textit{tradeoff} sobre o desempenho, confiabilidade e consumo energético das STT-RAM, aplicados aos requisitos no nível de arquitetura. No trabalho é apresentada a modelagem da STT-RAM para a redução do tempo de retenção dos dados. O objetivo é a aplicação em níveis mais específicos da hierarquia de memória, com foco em \textit{caches on-chip}.

Primeiramente é feita uma análise para verificar quais são os impactos na quebra da não volatilidade da STT-RAM, para isso é realizada uma simulação de três diferentes desenhos do MTJ com $45$x$95nm$ de tamanho. São realizadas duas otimizações da \textit{baseline}, chamadas de Opt1 e Opt2. Sendo a \textit{baseline} com seu tempo de retenção de dados de 4.27 anos e os outros dois otimizados para chaveamento (quando menor o tempo de retenção dos dados, menor o tempo necessário para chaveamento). Nos testes faz-se perceber que ao reduzir o tempo de retenção dos dados de 4 anos para $265 \mu s$, a corrente decai de $164.5 \mu A$ para $71.4 \mu A$ para um tempo de chaveamento de $10ns$ e temperatura de $350K$. Ao se colocar uma corrente de $125 \mu A$ o tempo de chaveamento dos três MJTs varia de $29.8ns$ para $3.6ns$, um ganho de até 8 vezes.

É demostrando também a dependência da temperatura. A estabilidade da barreira magnética do MJT é sensível a temperatura de trabalho, assim, ao se aumentar a temperatura de $275K$ para $350K$ a corrente de chaveamento tende a diminuir. Logo após, o trabalho apresenta estatísticas de padrão de acesso a \textit{cache}. Uma simulação é feita em um processador \textit{quad-core} sobre as seguintes configurações de \textit{cache} L1 de dados e L2:

\begin{table}[]
\centering
\begin{tabular}{lcc}
\hline
& \multicolumn{1}{l}{\textit{Cache} de dados L1} & \multicolumn{1}{l}{\textit{Cache} L2} \\ \hline
Tamanho (Bytes) & 32768 & 4194304 \\ \hline
Associatividade & 8 & 16 \\ \hline
Tamanho do bloco (bytes) & 64 & 64 \\ \hline
Latência de Leitura (ciclos) & 3 & 14 \\ \hline
\end{tabular}
\caption{Configuração das \textit{caches} L1 de dados e L2, para a simulação.}
\label{my-label}
\end{table} 

O teste é realizado usando quatro aplicações do SPEC \textit{benchmark} que são: 401.bzip2, 433.milc, 434zeusmp e 470lbm. Cada uma destas aplicações é executada em um \textit{core} diferente, sendo simulado um total de 2 bilhões de instruções. Para a \textit{cache} L1 mais de 95\% dos dados são acessados nos primeiros $10^{5}$ ciclos de \textit{clock}, após isto, estes dados são carregados ou atualizados. Em alguns casos, como no \textit{benchmark} 401.bzip2 o número pode alcançar até 99\% e que comportamentos similares se apresentaram na \textit{cache} L2. Estas observações demostram que uma pequena porção da \textit{cache} de dados será ativa por longos períodos, como exemplo do \textit{benchmark} 401.bzip2 que o tempo entre uma escrita e o último tempo em que os dados são lidos, excede $10^6$ ciclos de \textit{clock}. Este tempo entre leitura e escrita é utilizado para determinar o tempo mínimo de retenção de dados pelo MTJ.

No final é apresentado um modelo de \textit{cache} híbrida conjunto associativa com $n$-vias, onde a mesma é dividida em dois modelos de MTJ, um com baixa retenção de dados (utilizando os dados apresentados anteriormente) e outra com alta retenção. Cada bloco da \textit{cache} otimizada contém um contador que verifica quanto tempo os dados estão armazenados no bloco. Caso estes estejam por muito tempo, o sistema copia os dados da \textit{cache} otimizada para a não otimizada. Para avaliar o desempenho, este novo modelo é comparado a um usando STT-RAM sem otimização. Os resultados mostram que usando metade das vias de uma \textit{cache} L2 com 16 vias otimizada, o desempenho do novo modelo chega a ser 80\% melhor. A conclusão é que a redução da não volatilidade da STT-RAM e o uso de uma \textit{cache} híbrida, podem aumentar o desempenho e reduzir o consumo energético. Estas conclusões são retiradas da análise do modelo proposto e os testes realizados com os \textit{benchmarks}.

% Sun2011 %

Em \cite{Sun2011} também é apresentada a proposta de implementação de \textit{caches} híbridas, porém é apresentada a preocupação com a correta retenção dos dados na STT-RAM. Para se conseguir latências de escrita suficientemente baixas, é necessário reduzir muito o período de retenção dos dados, sendo que dependendo do tempo que o dado vai permanecer na \textit{cache}, um processo de \textit{refresh} dos dados acaba se tornando necessário. Assim é proposta a implementação de um sistema de \textit{refresh} dinâmico. Para cada bloco da \textit{cache} é inserido um contador que monitora o tempo de retenção dos dados, se nenhuma escrita/leitura ocorre em um determinado período limite pré definido, um \textit{refresh} ocorre. A ideia do uso do contador é para evitar a necessidade de \textit{refreshes} desnecessários.

Uma \textit{cache} com dois modelos de MTJ é proposto, um com baixa e outro com alta retenção. Os dados são movidos das regiões de alta para as de baixa retenção, ou vice versa, através das seguintes políticas: 
\begin{itemize}
\item \textit{Write Intensive}: se a intensidade de escrita é alta, e os dados se encontram em uma região de alta retenção, os dados são migrados para uma região de baixa.
\item \textit{Read intensive}: se os dados se encontram em uma região de baixa retenção, então estes são migrados para uma região de alta.
\item \textit{Neither write nor read intensive}: Os dados são mantidos em uma região de alta retenção ou migrados para memória principal. 
\end{itemize}

A principal ideia para a migração de regiões de memória está ligada também a redução de \textit{refreshes}, já que o modelo de \textit{refresh} utilizado no modelo proposto é o mesmo utilizado em memórias DRAM.

Para os testes, são simulados três modelos de otimização de MTJ, um com baixa (lo), média (md) e alta retenção (hi). Em uma arquitetura \textit{quad-core} com três níveis de \textit{cache} L1, L2 e L3, ambas usando STT-RAM. Os resultados dos testes mostram que a melhor configuração para uma hierarquia de dois níveis (L1 e L2) é usando L1-lo e uma L2 hibrida com L2-lo para região de baixa retenção e L2-md para a região de alta. Já para uma \textit{cache} de 3 níveis a melhor configuração se deu usando L1-lo, L2-lo com L2-md e una L3 com a configuração de uma L1-lo para a região de baixa retenção e L3-md para região de alta.

Os resultados dos testes mostram que o uso das \textit{caches} híbridas propostas utilizando os métodos de \textit{refresh} apresentados, tem um ganho de desempenho de até 99.8\% se comparada ao uso de um SRAM convencional. Já no quesito consumo de energia, o modelo apresentado tem ganhos de até 70\% se comparado a outros trabalhos e.g~\cite{Smullen2011}. O trabalho conclui que o uso de memórias híbridas (baixa e alta retenção) apresentam ganhos não somente em desempenho como também em consumo de energia. O uso de múltiplos níveis de retenção podem alcançar uma redução de até 73.8\% de redução de energia se comparado a implementações que mesclam SRAM/STT-RAM e se comparado a outros trabalhos anteriores que apresentam o uso de STT-RAM, consegue um aumento de desempenho de até 5.5\% e uma redução energética de até 30\%.

% Jog2012 %

O trabalho exibido em~\cite{Jog2012} tem o foco de ajustar o tempo de retenção de dado em memória de acordo com o tempo necessário para execução do \textit{refresh} da \textit{cache} de último nível (\textit{Last Level Cache} -- LLC), com a finalidade de obter ganhos no desempenho e energia. São propostos e estudados três modelos de STT-RAM: (i) um sem reduzir a retenção, (ii) outro o qual tem seu tempo de retenção reduzido para $1s$, considerado grande o bastante para o tempo de escrita da maioria das linhas de \textit{cache}, não acarretando em \textit{overhead}. E por fim, (iii) um modelo com tempo de retenção de $10ms$ o qual é necessário utilizar uma técnica de \textit{refresh}, embora a latência e consumo de energia sejam menores para efetuar uma escrita neste caso.

A STT-RAM volátil neste caso funciona de maneira simplificada: Todos os blocos os quais após um determinado tempo estão por perder o dado, efetua-se um \textit{write-back} nos mesmos, utilizando-se de um contador de poucos \textit{bits}. Esta abordagem acaba prejudicando o desempenho por que ao final do tempo de retenção, existirão diversos \textit{write-backs}, causando um grande \textit{overhead}. Além disto, se um bloco o qual é constantemente lido perder a informação, haverá maior quantidade de \textit{misses} de leitura na \textit{cache}. Para contornar principalmente o primeiro problema, é proposta a técnica de \textbf{\textit{Cache Revive}}, o qual adiciona um pequeno \textit{buffer} que amortiza as custosas escritas que seriam feitas diretamente na STT-RAM.

Os resultados deste trabalho procuram avaliar, dentre os três modelos, algumas configurações de estudo de cache, as quais foram: S-1 (SRAM de $1MB$); S-4 (Caso hipotético onde a SRAM tem $4MB$, porém apresenta a mesma latência de operação de S-1); M-4 (STT-RAM não volátil); V-M-4($1s$) (STT-RAM volátil com tempo de retenção de $1s$); V-M-4($10ms$) (STT-RAM volátil com tempo de retenção de $10ms$) e R-M-4($10ms$) (STT-RAM volátil utilizando a técnica de \textit{cache revive}). 

Em questões de desempenho, em média o desempenho de R-M-4 ($10ms$) só perde para o modelo hipotético S-4, tendo \textit{speedup} de quase 20\% ao simular os \textit{benchmarks} do PARSEC se comparados com o \textit{baseline} S-1. Analisando o consumo energético, percebe-se um ganho de 44\% na configuração M-4 para a S-1, o que é esperado dado que a STT-RAM gera pouca fuga de energia. Ao tornar a STT-RAM volátil, tem-se maior fuga de energia, ainda que inferior se comparada a SRAM. Na média, há ganhos em energia de 11\% no caso de estudo R-M-4 ($10ms$) comparado com V-M-4($1s$), além de melhoria em 18\% na energia em relação à configuração M-4 (\textit{baseline} da STT-RAM), concluindo assim que energeticamente o uso de STT-RAM volátil com o esquema de \textit{cache revive} atingiu os melhores resultados na média.

% Li2013 %

Em~\cite{Li2013}, propõe-se uma técnica chamada de CCear (\textit{Cache Coherence Enabled Adaptative Refresh}) a qual visa reduzir a quantidade de \textit{refreshes} em uma STT-RAM volátil. Este trabalho tem como diferencial obsevar a informação de coerência dos blocos de \textit{cache} L2 com a finalidade de atenuar o \textit{overhead} gerado por operações de \textit{refresh} na memória. Dentro da técnica de CCear, em cada bloco que é compartilhado são feitas $n$ operações de \textit{refreshes} após o carregamento da memória principal ou depois de um \textit{write-back} da \textit{cache} L1.

Utilizando-se do CCear, é feito um comparativo do uso de uma arquitetura com suporte a este mecanismo com a política de DRAM \textit{refresh} proposta em~\cite{Smullen2011}, sendo analisadas as questões energéticas e o IPC (Instruções por ciclo). Além destes dois casos, o trabalho ainda exibe resultados do que seria a situação ideal para a implementação de STT-RAM voláteis. Na energia, o modelo de DRAM \textit{refresh} exibe consumo alto se comparado ao caso ideal, enquanto que ao usar o CCear há uma redução em relação à política de DRAM \textit{refresh} na média em cerca de 10\%. Avaliando o IPC, utilizando CCear existe uma melhora no IPC comparado ao DRAM \textit{refresh} entre cerca de 3\% a 7\%, ocorrido devido à menor quantidade de conflitos entre \textit{refreshes} e leituras na \textit{cache}.

O artigo conclui dizendo que o \textit{overhead} para armazenamento de informações necessárias para o funcionamento do CCear é desprezível - Inicialmente, é de menos de 0,2\%, visto que cada bloco da LLC precisa de um bit para indicar se está expirado ou não. Além disto, cada bloco da LLC também usa um contador de 4 \textit{bits} para controlar quantos \textit{refreshes} são feitos. Também conclui que o CCear pode adaptativamente minimizar a quantidade de operações de \textit{refresh} necessárias para o uso de STT-RAM volátil.

% Chang2013 %

Já o trabalho apresentado por \cite{Chang2013}, é realizada uma comparação entre três diferentes tipos de memórias aplicadas ao último nível de \textit{cache}, são elas a SRAM, STT-RAM e eDRAM. A ideia é otimizar a SRAM para baixa corrente de fuga, a STT-RAM para baixo consumo energético de escrita e a eDRAM usando a ideia de \textit{dead-line prediction} para reduzir a quantidade de \textit{refreshes} desnecessários. A implementação proposta de STT-RAM neste trabalho é um MTJ com retenção de apenas 1 segundo, não são experimentados outros tempos de retenção de dados devido a necessidade de \textit{buffers} e unidades de \textit{refresh} para manter os dados corretamente armazenados. Os autores não se preocupam com isso porque o foco principal do artigo é o uso de eDRAMs.

Para os testes é simulada uma arquitetura com 8 \textit{cores} e três níveis de \textit{cache} onde, L1 e L2 são \textit{caches} usando SDRAM de alto desempenho e L3 é uma \textit{cache} de 32Mb, este último nível de \textit{cache} com os três diferentes tipos de memória (SDRAM, STT-RAM e eDRAM). Os resultados mostram que o uso de STT-RAM consome até 48\% menos energia que o uso de SRAM, contudo se a quantidade de escritas na memória é alta, STT-RAM consome maior quantidade de energia. Para cargas de trabalho com escrita intensiva a eDRAM se mostrou melhor na questão de consumo energético, ficando 36\% mais eficiente que a SRAM de baixo consumo e 17\% comparado a STT-RAM. No quesito desempenho, em média SDRAM apresenta os melhores tempos, porem em cargas de trabalhos dominadas por leituras, STT-RAM apresentam melhores resultados que as demais. 

Outra observação feita no trabalho são os impactos que o tamanho e tecnologia exercem sobre as memórias. Caches que possuem alta densidade de memória usando STT-RAM tendem a apresentar menor consumo de energia. Isso se dá pelo fato de que quanto maior a \textit{cache} em média, menor será o número de \textit{cache miss}, sendo assim menor o número de atualizações. No quesito tecnologia, quanto menor a célula STT-RAM, menor sera o consumo de energia, pois o tempo de escrita será menor. STT-RAM com tecnologia de $22nm$ são mais eficientes energeticamente do que as de $45nm$, porém o tempo de retenção pode sofrer perda de estabilidade devido a instabilidade térmica.

Como conclusão os autores demostram que o uso de eDRAM com a técnica de \textit{dead-line prediction} apresentou os melhores resultados, porém a necessidade de \textit{caches} de desempenho elevado e alta densidade serão necessárias no futuro. Assim o uso de novas tecnologias como a eDRAM e a STT-RAM são promissoras.

% Li2015 %

\newcommand{\nr}{$N$-\textit{refresh}}
\newcommand{\nrdl}{$N$-\textit{refresh}-DL}

No trabalho de \cite{Li2015}, também é proposta uma \textit{cache} usando STT-RAM com baixo tempo de retenção de dados e com a necessidade de \textit{refresh}. Porém o trabalho vai além, neste os autores se preocupam com a ordenação dos dados na \textit{cache} para reduzir o número de \textit{refreshes}. No trabalho é proposto uma ordenação dos dados em tempo de compilação para extrair os benefícios da STT-RAM e ao mesmo tempo reduzir o consumo de energia através da redução da quantidade de \textit{refreshes} na memória. O trabalho propõe uma nova metodologia de \textit{refresh} para memória chamado de~\nr. Os dados que são escritos mas não são utilizados por um grande período de tempo ou sofrem uma reescrita, após um determinado tempo limite, são migrados para a memória principal, descartando assim a necessidade de \textit{refresh} da \textit{cache}. Também são propostos dois modelos de organização de dado em memória no código compilado, são eles: ILP - \textit{Integer Linear Programming}(ILP) e \textit{Heuristic Data Layout}(DL), ambos utilizam técnicas sub-ótimas para ordenar os dados entre os blocos da \textit{cache}.

Para os experimentos os autores simulam uma arquitetura de um processador \textit{single-core} de 500Mhz e com uma \textit{cache} de 16Mb, com blocos de 32b com 4 vias. Tempo de retenção de dados de $26.5\mu s$. O metodo de \textit{refresh} e as técnicas de otimização em tempo de compilação são empregadas em outros dois metodos de \textit{refresh} presentes na literatura~\cite{Sun2011,Jog2012}. 

Os resultados demostram que o uso da técnica~\nrdl, reduziu em apenas 2.0\% a quantidade de \textit{refreshes} se comparado a mesma técnica sem o uso de heurística (somente usando~\nr). Porém os outros métodos já conseguiram melhores resultados se comparado a outros modelos da literatura, alcançando melhorias de até 38.0\%.

Também é feito a análise da técnica apresentada a diferentes características da \textit{cache} como tamanho, tamanho do bloco, latência de escrita, tempo de retenção e o mudanças no tempo de \textit{refresh}. Para tamanhos de blocos pequenos, as técnicas apresentadas fornecem melhores desempenhos por explorar melhor a localidade dos dados, porém para \textit{caches} com blocos pequenos a perda de desempenho devido a baixa taxa de \textit{cache hit}, já para blocos grandes as técnicas não apresentam ganhos.

Em relação ao tamanho da \textit{cache}, quanto maior a \textit{cache}, maior se torna a quantidade de \textit{refresh} necessários contudo, o método de organização dos dados, aproveita melhor o espaço da \textit{cache}. Assim, aumentar o tamanho da \textit{cache}, não surte efeito no desempenho, pois a nova área de memória quase não é utilizada. Já em relação ao aumento da quantidade de \textit{refresh}, a taxa de \textit{cache hit} aumenta pois menos blocos se tornam invalidados em decorrência da baixa retenção.

Os dois últimos itens (latência de escrita e retenção), quanto maior a latência de escrita maior é o tempo de execução do código e maior se torna a quantidade de \textit{refresh} necessários, assim baixas latências de escrita apresentam melhores rendimentos. Quanto a retenção, quanto maior a retenção dos dados, menor são as taxas de \textit{refresh} necessárias, porém a uma degradação no uso das técnicas de localidade de dados, pois a menos espaço para a otimização se torna limitado.

Como conclusão, o trabalho expõem que os métodos propostos apresentam melhor rendimento energético, por explorar melhor a localidade dos dados e diminuir a quantidade de \textit{refresh} necessário e mantém um desempenho equivalente as técnicas apresentadas em outros trabalhos. 

% Qiu2016 % 

No trabalho de~\cite{qiu2016}, é proposto um método de escalonamento de \textit{loops} para melhorar a localidade dos dados na memória e assim reduzir a quantidade de \textit{refresh}. O trabalho propõem que os dados sejam acessados em uma determinada ordem, fazendo com que estes sejam "realimentados" por uma leitura e ou uma escrita. Isto se dá pelo fato de que, se o tempo de escrita/leitura é menor que o tempo de retenção dos dados na STT-RAM, o \textit{refresh} se torna dispensável. Os autores defendem o fato de que alinhando os dados em memória em uma determinada forma, reduz-se a quantidade de energia consumida e aumenta-se o desempenho.

Os testes realizados foram a simulação de microcontrolador acessando uma memória STT-RAM externa. Foram avaliadas três frequências de operação diferentes (100, 200 e 500MHz) e escalas de \textit{loops} de 100x100(x100), 200x200(x200), 500x500(x500) e 1000x1000(x1000). Em média a técnica de escalonamento de \textit{loops} os ciclos de acesso a memória (incluindo \textit{refresh}) são reduzidos em 54.6\%(100x100), 68.7\%(200x200),82.7\%(500x500) e 89.1\%(1000x1000), em todas as frequencias testadas.

Já no consumo de energia dinâmica, as técnicas reduziram a energia consumida em 85.0\% para 100Mhz, 75.8\% em 200Mhz e 59.5\% em 500Mhz. A explicação para esta redução de energia está no fato de que, quanto menor a frequência, maior se torna o tempo de escrita em memória, assim o espaço de otimização do \textit{loop} é maior, alcançando melhores resultados. Outro item é o tamanho dos \textit{loops}, quanto maior a escala do \textit{loop} (1000x1000) maior se torna a distância entre uma leitura após uma escrita, assim a técnica de reescalonamento de \textit{loops} apresenta melhores resultados, por reordenar estes acessos.

Uma outra observação é feita no trabalho. O quanto o tempo de retenção dos dados ajuda a reduzir o consumo de energia e aumenta o desempenho. Observa-se que quanto maior o tempo de retenção, o escalonamento de \textit{loops} perde desempenho. Isso se dá pelo fato de que, o número de iterações do \textit{loop} comparado ao tempo de retenção é muito menor, assim, mais atualizações se tornam necessárias na memória, prejudicando assim o uso da técnica.

Como conclusão, o trabalho expõe o problema do \textit{overhead} criado pelos sistemas de \textit{refresh} em memória, o que pode degradar tanto o desempenho quanto o consumo energético. Com o intuito de reduzir a necessidade de \textit{refresh} em memória, o escalonamento de \textit{loops}, para melhor a alocação e acesso de dados na memória se torna uma técnica promissora.
